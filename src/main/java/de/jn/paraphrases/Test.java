package de.jn.paraphrases;

import java.io.FileNotFoundException;
import java.io.FileReader;
import java.util.ArrayList;
import java.util.List;

import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.ling.HasWord;
import edu.stanford.nlp.process.CoreLabelTokenFactory;
import edu.stanford.nlp.process.DocumentPreprocessor;
import edu.stanford.nlp.process.PTBTokenizer;

/**
 * Created by jan on 12.09.17.
 */
public class Test {

    public static void main(String[] args) throws FileNotFoundException{
//        String html = "<td>abcd<br/>bla<hr>bla</td>";
//        int index = html.toLowerCase().indexOf("<hr>");
//        System.err.println(html);
//        String trim = html.substring(0,index) + "</td>";
//        System.err.println(trim);
//
//        Document doc = Jsoup.parse(trim);
//        System.err.println(doc.text());
    	
    	
//    	List<String> p = Arrays.asList("a", "b", "c", "d", "e");
//    	List<String> s = Arrays.asList("a", "c", "e", "g");
//    	
//    	List<String> unavailable = p.stream()
//                .filter(e -> s.contains(e))
//                .collect(Collectors.toList());
//    	
//    	System.out.println(unavailable);
    	
    	
    	// STANFORD CORENLP
//        Properties props = new Properties();
//        props.setProperty("annotators", "tokenize, ssplit, pos, lemma, ner, parse, dcoref");
//        StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
//
//        // read some text in the text variable
//        String text = "...";
//
//        // create an empty Annotation just with the given text
//        Annotation document = new Annotation(text);
//
//        // run all Annotators on this text
//        pipeline.annotate(document);

    	
}
}
