{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pymysql\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import random\n",
    "from langdetect import detect\n",
    "import csv\n",
    "import MySQLdb\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def execute_sql(conn, query):\n",
    "    cur = conn.cursor(MySQLdb.cursors.DictCursor)\n",
    "    cur.execute(query)\n",
    "    return cur\n",
    "\n",
    "conn = MySQLdb.connect(host='127.0.0.1', user='root', passwd=\"\", db='vroniplag', charset='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_query_monolingual_table(word_ratio_min, word_ratio_max, len_min, bow_diff_min=1):\n",
    "    query = \"CREATE TABLE monolingual AS SELECT annotation_identifier, url, \"\n",
    "    query += \"plagiat_sent, source_sent, fake_source_sent, lang_plagiat, lang_source, \"\n",
    "    query += \"bow_diff, nb_words_ratio \"\n",
    "    query += \"from annotationAugmented \"\n",
    "    query += \"WHERE category='Verschleierung' and lang_plagiat=lang_source and \"\n",
    "    query += \"nb_words_ratio>\" + str(word_ratio_min) + \" and nb_words_ratio<\" + str(word_ratio_max) + \" and \"\n",
    "    query += \"length(plagiat_sent)>\" + str(len_min) + \" and length(source_sent)>\" + str(len_min) + \" and \"\n",
    "    query += \"bow_diff>\" + str(bow_diff_min)\n",
    "    query += \";\"\n",
    "    print(query)\n",
    "    return query\n",
    "\n",
    "def get_query_monolingual_lang_table(tablename, lang):\n",
    "    query = \"CREATE TABLE \" + tablename + \" as SELECT annotation_identifier, url, plagiat_sent, source_sent, \"\n",
    "    query += \"bow_diff, nb_words_ratio \"\n",
    "    query += \"from monolingual where lang_plagiat='\" + lang + \"' and lang_source='\" + lang + \"';\"\n",
    "    print(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_from_monolingual_table(lang, keys, isParaphrase, excludeInnerIdenticals=False):\n",
    "    query = \"SELECT * from monolingual\" + lang.upper() + \" WHERE isParaphrase=\" + str(isParaphrase) + \";\"\n",
    "    cur = execute_sql(conn, query)\n",
    "    rows = []\n",
    "    counter = 0\n",
    "    for row in cur:\n",
    "        #if row['annotation_identifier'] != \"Aaf/Fragment 009 01_7\":\n",
    "        #    continue\n",
    "            \n",
    "        new_row = []\n",
    "        for key in keys:\n",
    "            val = row[key]\n",
    "            #print(type(val))\n",
    "            if type(val)==unicode:\n",
    "                #print(val)\n",
    "                #val = val.decode('latin-1').encode(\"utf-8\")\n",
    "                val = val.encode(\"utf-8\")\n",
    "                #print(val)\n",
    "                #print(\"\")\n",
    "                \n",
    "            new_row.append(val)\n",
    "        if excludeInnerIdenticals:\n",
    "            plag = row['plagiat_sent'].lower()\n",
    "            src = row['source_sent'].lower()\n",
    "            if plag in src or src in plag:\n",
    "                counter += 1\n",
    "                continue    \n",
    "        rows.append(new_row)\n",
    "    \n",
    "    print(\"# skipped (inner identicals): \" + str(counter))\n",
    "    return rows\n",
    "\n",
    "def split_data(percent_test, data):\n",
    "    split = int(percent_test * len(data))\n",
    "    test_data = data[:split+1]\n",
    "    train_data = data[split+1:]\n",
    "    return train_data, test_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include negative paraphrase pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addValToQuery(vals, query):\n",
    "    for idx, key in enumerate(vals):\n",
    "        if idx==len(vals)-1:\n",
    "            query += str(key) + \") \"\n",
    "        else:\n",
    "            query += str(key) + \", \"\n",
    "    return query\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addNegatives(conn, tablename, fakeSrcDict):\n",
    "\n",
    "    cur = execute_sql(conn, \"SELECT * from \" + tablename + \" WHERE isParaphrase=1;\")\n",
    "    for row in cur:\n",
    "        annotation_id = row['annotation_identifier']\n",
    "        fake_src = fakeSrcDict[annotation_id]\n",
    "        if not fake_src: continue\n",
    "        row['annotation_identifier'] = annotation_id + \"_f\"\n",
    "        row['source_sent'] = fake_src\n",
    "        row['isParaphrase'] = 0\n",
    "        \n",
    "        query = \"INSERT INTO \" + tablename + \" (\"\n",
    "        query = addValToQuery(row.keys(), query)\n",
    "        query += \" VALUES (\"\n",
    "        values = []\n",
    "        for item in row.values():\n",
    "            if type(item) == str:\n",
    "                item = item.replace(\"'\",\"\\\\'\")\n",
    "            values.append(\"'\"+str(item)+\"'\")\n",
    "                \n",
    "        query = addValToQuery(values, query)\n",
    "        query += \";\"\n",
    "        try:\n",
    "            cur2 = conn.cursor()\n",
    "            cur2.execute(query)\n",
    "            cur2.close()\n",
    "        except Exception as e:\n",
    "            ## Fehler passieren durch Abostrophe im Text ... \n",
    "            print(row['url'])\n",
    "            if row['url'] == 'http://de.vroniplag.wikia.com/wiki/Ww/Fragment_016_01' or row['url'] == 'http://de.vroniplag.wikia.com/wiki/Yb/Fragment_186_14':\n",
    "                print(query)\n",
    "\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fake Sources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get mapping from annotation_identifier to fake source sent\n",
    "def getFakeSources(lang):\n",
    "    query = \"SELECT * from monolingual WHERE lang_plagiat='\"+lang+\"' and lang_source='\"+lang+\"';\"\n",
    "    cur_annotation = execute_sql(conn, query)\n",
    "    ids_to_fake_sources = {}\n",
    "    for row in cur_annotation:\n",
    "        key = row['annotation_identifier']\n",
    "        ids_to_fake_sources[key] = row['fake_source_sent']\n",
    "\n",
    "    return ids_to_fake_sources\n",
    "    cur_annotation.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate CSV-Files in UTF-8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skipped (inner identicals): 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data_from_monolingual_table('es', keys, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_csv_files(lang, keys):\n",
    "    data_isPP = get_data_from_monolingual_table(lang, keys, 1)\n",
    "    print(\"nb paraphrases: \" + str(len(data_isPP)))\n",
    "    data_noPP = get_data_from_monolingual_table(lang, keys, 0)\n",
    "    print(\"nb fake-paraphrases: \" + str(len(data_noPP)))\n",
    "\n",
    "    train_data_isPP, test_data_isPP = split_data(0.2, data_isPP)\n",
    "    train_data_noPP, test_data_noPP = split_data(0.2, data_noPP)\n",
    "\n",
    "    train_data = pd.DataFrame(train_data_isPP + train_data_noPP,columns=keys)\n",
    "    test_data = pd.DataFrame(test_data_isPP + test_data_noPP, columns=keys)\n",
    "\n",
    "    print(\"train shape: \" + str(train_data.shape))\n",
    "    print(\"test shape: \" + str(test_data.shape))\n",
    "    train_data.to_csv(lang+'_train.csv', encoding='utf-8')\n",
    "    test_data.to_csv(lang+'_test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enrich the *annotation*-table with the columns **category**, **lang_source** and **lang_plagiat** from the *fragment*-table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE annotationAugmented AS SELECT * from annotation\"\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALTER TABLE annotationAugmented ADD COLUMN lang_source VARCHAR(80), ADD COLUMN lang_plagiat VARCHAR(80), ADD COLUMN category VARCHAR(80);\n"
     ]
    }
   ],
   "source": [
    "query = \"ALTER TABLE annotationAugmented ADD COLUMN lang_source VARCHAR(80), ADD COLUMN lang_plagiat VARCHAR(80), \"\n",
    "query += \"ADD COLUMN category VARCHAR(80);\"\n",
    "print(query)\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 processed\n",
      "1000 processed\n",
      "2000 processed\n",
      "3000 processed\n",
      "4000 processed\n",
      "5000 processed\n",
      "6000 processed\n",
      "7000 processed\n",
      "8000 processed\n",
      "9000 processed\n",
      "10000 processed\n",
      "11000 processed\n",
      "12000 processed\n",
      "13000 processed\n",
      "14000 processed\n",
      "15000 processed\n"
     ]
    }
   ],
   "source": [
    "# Insert data\n",
    "cur_fragment = execute_sql(conn, \"SELECT * from fragment\")\n",
    "count=0\n",
    "for row in cur_fragment:\n",
    "    url = row['url']\n",
    "    lang_original = row['lang_source']\n",
    "    lang_plagiat = row['lang_plagiat']\n",
    "    category = row['category']\n",
    "    query = \"UPDATE annotationAugmented SET lang_source='\" + lang_original + \"', lang_plagiat='\" + lang_plagiat;\n",
    "    query += \"', category='\" + category;\n",
    "    query += \"' WHERE url='\" + url + \"';\"\n",
    "    execute_sql(conn, query)\n",
    "    if(count % 1000 == 0):\n",
    "        print(\"{0} processed\".format(count))\n",
    "    count+=1\n",
    "    \n",
    "conn.commit()\n",
    "cur_fragment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Monolingual database from *annotationAugmented*-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE monolingual AS SELECT annotation_identifier, url, plagiat_sent, source_sent, fake_source_sent, lang_plagiat, lang_source, bow_diff, nb_words_ratio from annotationAugmented WHERE category='Verschleierung' and lang_plagiat=lang_source and nb_words_ratio>0.5 and nb_words_ratio<1.5 and length(plagiat_sent)>70 and length(source_sent)>70 and bow_diff>6;\n"
     ]
    }
   ],
   "source": [
    "query = get_query_monolingual_table(0.5, 1.5, 70, 6)\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = ['plagiat_sent', 'source_sent', 'isParaphrase', 'url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MonolingualEN**-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE monolingualEN as SELECT annotation_identifier, url, plagiat_sent, source_sent, bow_diff, nb_words_ratio from monolingual where lang_plagiat='en' and lang_source='en';\n"
     ]
    }
   ],
   "source": [
    "query = get_query_monolingual_lang_table(\"monolingualEN\", \"en\")\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"ALTER TABLE monolingualEN ADD COLUMN isParaphrase TINYINT(1) DEFAULT 1\"\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids_to_fake_sources = getFakeSources(\"en\")\n",
    "addNegatives(conn, \"monolingualEN\", ids_to_fake_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skipped (inner identicals): 0\n",
      "nb paraphrases: 1938\n",
      "# skipped (inner identicals): 0\n",
      "nb fake-paraphrases: 1580\n",
      "train shape: (2813, 4)\n",
      "test shape: (705, 4)\n"
     ]
    }
   ],
   "source": [
    "# write train and test csv files\n",
    "write_csv_files(\"en\", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MonolingualDE**-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE monolingualDE as SELECT annotation_identifier, url, plagiat_sent, source_sent, bow_diff, nb_words_ratio from monolingual where lang_plagiat='de' and lang_source='de';\n"
     ]
    }
   ],
   "source": [
    "query = get_query_monolingual_lang_table(\"monolingualDE\", \"de\")\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"ALTER TABLE monolingualDE ADD COLUMN isParaphrase TINYINT(1) DEFAULT 1\"\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids_to_fake_sources = getFakeSources(\"de\")\n",
    "addNegatives(conn, \"monolingualDE\", ids_to_fake_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skipped (inner identicals): 0\n",
      "nb paraphrases: 12932\n",
      "# skipped (inner identicals): 0\n",
      "nb fake-paraphrases: 10935\n",
      "train shape: (19092, 4)\n",
      "test shape: (4775, 4)\n"
     ]
    }
   ],
   "source": [
    "# write train and test csv files\n",
    "write_csv_files(\"de\", keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MonolingualES**-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE monolingualES as SELECT annotation_identifier, url, plagiat_sent, source_sent, bow_diff, nb_words_ratio from monolingual where lang_plagiat='es' and lang_source='es';\n"
     ]
    }
   ],
   "source": [
    "query = get_query_monolingual_lang_table(\"monolingualES\", \"es\")\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"ALTER TABLE monolingualES ADD COLUMN isParaphrase TINYINT(1) DEFAULT 1\"\n",
    "cur = execute_sql(conn, query)\n",
    "conn.commit()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Einbauen, dass jedes annotation_identifier nur einmal eingefügt werden darf!! D.h. jedes negative Beispiel darf\n",
    "### nur einmal eingebaut werden!!\n",
    "# MonolingualES\n",
    "ids_to_fake_sources = getFakeSources(\"es\")\n",
    "addNegatives(conn, \"monolingualES\", ids_to_fake_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# skipped (inner identicals): 0\n",
      "nb paraphrases: 7\n",
      "# skipped (inner identicals): 0\n",
      "nb fake-paraphrases: 5\n",
      "train shape: (8, 4)\n",
      "test shape: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "# write train and test csv files\n",
    "write_csv_files(\"es\", keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
